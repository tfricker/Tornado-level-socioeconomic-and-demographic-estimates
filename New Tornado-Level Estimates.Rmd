---
title: "Tornado-Level Estimates using Areal"
author: "Tyler Fricker"
date: "1/14/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

Set working directory and load packages.
```{r}
library(tidyverse)
library(lubridate)
library(sf)
library(tmap)
library(USAboundaries)
library(rgeos)
library(rgdal)
library(areal)
library(tidycensus)
```

### Data and Methods

Tornado data:

Download the tornado data from the Storm Prediction Center (SPC) http://www.spc.noaa.gov/gis/svrgis/ and load the shapefile into R.
```{r}
#download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-aspath.zip",
#              destfile = "tornado2017.zip")
#download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-initpoint.zip",
#              destfile = "tornado2017.zip")
#unzip("tornado2017.zip")
TornL.sf <- read_sf(dsn = "1950-2017-torn-aspath",
                   stringsAsFactors = FALSE)
TornP.sf <- read_sf(dsn = "1950-2017-torn-initpoint",
                   stringsAsFactors = FALSE)
```

The Paths data set has missing geometries, while the points data set does not.
```{r}
any(is.na(st_dimension(TornL.sf)))
any(is.na(st_dimension(TornP.sf)))
```

Merge the two data sets. Insert point geometries where there are missing linestring geometries.
```{r}
Torn.sf <- TornL.sf
eg <- which(st_is_empty(Torn.sf))
Torn.sf$geometry[eg] <- TornP.sf$geometry[eg]
```

Remove tornadoes occurring in Hawaii, Alaska, and Puerto Rico and those occurring before 1994. That year marks the beginning of comprehensive WSR-88D radar coverage. For missing EF ratings use the modification rules (if/else) defined here: https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf
```{r}
Torn.sf <- Torn.sf %>%
  filter(yr >= 1995,
         !st %in% c("AK", "PR", "HI")) %>%
  mutate(mag = ifelse(mag == -9 & len <= 5, 0, mag),
         mag = ifelse(mag == -9 & len > 5, 1, mag))
```

Add a data/time column also add columns for path length, width, and area in metric units. Leave the time zone as native CDT.
```{r}
Torn.sf <- Torn.sf %>%
  mutate(dy = format(as.Date(date, format="%Y-%m-%d"), "%d"),
         DateTime = as.POSIXct(paste(yr, mo, dy, time), format = "%Y%m%d%H:%M:%S"),
         Hour = hour(DateTime),
         Year = year(DateTime),
         Length = len * 1609.34,
         Length = ifelse(Length == 0, min(Length[Length > 0]), Length), #takes care of zero length
         Width = wid * .9144,
         Width = ifelse(Width == 0, min(Width[Width > 0]), Width), #takes care of zero width
         Width = ifelse(Year >= 1995, Width * pi/4, Width), #takes care of change: avg to max
         cas = inj + fat,
         AreaPath = Length * Width,
         Ma = factor(month.abb[mo], levels = month.abb[1:12])) %>%
         filter(cas > 0 & Year <= 2016) %>%
  sf::st_sf()
max(Torn.sf$yr)
```

Add energy dissipation per tornado.
```{r}
perc <- c(1, 0, 0, 0, 0, 0, 
          .772, .228, 0, 0, 0, 0,
          .616, .268, .115, 0, 0, 0,
          .529, .271, .133, .067, 0, 0,
          .543, .238, .131, .056, .032, 0,
          .538, .223, .119, .07, .033, .017)
percM <- matrix(perc, ncol = 6, byrow = TRUE)
threshW <- c(29.06, 38.45, 49.62, 60.8, 74.21, 89.41)
midptW <- c(diff(threshW)/2 + threshW[-length(threshW)], threshW[length(threshW)] + 7.5)
ef <- Torn.sf$mag + 1
EW3 <- numeric()
for(i in 1:length(ef)) EW3[i] = midptW^3 %*% percM[ef[i], ]
Torn.sf <- Torn.sf %>%
  mutate(ED = EW3 * AreaPath)
```

Add tornado paths by buffering tornado tracks by associated widths.

To perform geocomputions we need to set coordinate reference system. Here it is geographic. We transform the geographic coordinate reference system to a specific Lambert conic conformal projection.
```{r}
Torn.sf <- st_transform(Torn.sf, 
                     crs = "+proj=lcc +lat_1=60 +lat_2=30 +lon_0=-90 +units=m")
```

Buffer the geometries.
```{r}
TornB.sf <- st_buffer(Torn.sf, 
                   dist = Torn.sf$Width/2,
                   endCapStyle = 'ROUND') %>%
  mutate(ID = 1:nrow(.))
```

Calculate the error in area between the estimated paths (AreaPath variable) and the buffered tornado tracks (tornado paths).
```{r}
((sum(TornB.sf$AreaPath) - sum(as.vector(st_area(TornB.sf))))/sum(Torn.sf$AreaPath)) * 100
```

Percent error is between 1.8% (square end caps) and 2.3% (round end caps).

Subset tornadoes from 1995--2016
```{r}
TornB.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year <= 2016)
```

Play with Areal Package and TidyCensus package. Start with a small set of the data and work up.

Socioeconomic/Demographic data:

Load API and variables from ACS. Here we use the 2000 Census summary file 3, and 2010 ACS 5-year estimates.
```{r}
census_api_key("2814de123d5d0461a3347a42849d25106688daa8", install = TRUE, overwrite = TRUE)
v90 = load_variables(1990, "sf3", cache = FALSE)
v00 = load_variables(2000, "sf3", cache = FALSE)
v10 <- load_variables(2010, "acs5", cache = FALSE)
v15 <- load_variables(2015, "acs5", cache = FALSE)
```

Create dataframes of all Tracts. The variables for the Census (2000) and ACS (2010) include:
----------------------------------------------------------------------------------

Total Population (P001001/B01001_001E)
-----------------------------------------
Male Population (P008002/B01001_002E)
Male Population (Under 17) (P008003-P008020/B01001_003E-B01001_006E)
Male Population (18-44) (P008021-P008029/B01001_007E-B01001_0014E)
Male Population (45-64) (P008030-P008034/B01001_015E-B01001_019E)
Male Population (Over 65) (P008035-P008040/B01001_020E-B01001_025E)
-----------------------------------------
Female Population (P008041/B01001_026E)
Female Population (Under 17) (P008042-P008059/B01001_027E-B01001_030E)
Female Population (18-44) (P008060-P008068/B01001_031E-B01001_038E)
Female Population (45-64) (P008069-P008073/B01001_039E-B01001_043E)
Female Population (Over 65) (P008074-P008079/B01001_044E-B01001_049E)
-----------------------------------------
White alone (P006002/B02001_002E)
-----------------------------------------
Black or African-American alone (P006003/B02001_003E)
-----------------------------------------
Household Median Income (P053001/B19013_001E)
-----------------------------------------
Housing Units (/B25024_001)
Mobile Homes (H030010/B25024_010E)
-----------------------------------------

Try downloading shapefile for Census tracts from IPUMS GIS.
```{r}
Tracts.sf <- read_sf(dsn = "2012_Tracts",
                   stringsAsFactors = FALSE)
```

Import IPUMS data
```{r}
us2010 <- read.csv("2012ACS.csv", header = TRUE)
```

Merge the two data sets and remove data from states outside of the contiguous U.S.
```{r}
US2010.sf <- us2010 %>%
  mutate(ID2 = 1:nrow(us2010),
    geometry = Tracts.sf$geometry[us2010$GISJOIN]) %>%
  st_as_sf()

#US2010.sf$ID2 = 1:nrow(US2010.sf)
#US2010.sf = st_as_sf(US2010.sf)

us <- unique(fips_codes$state_code)[c(1, 3:8, 10:11, 13:51)]
# Take care of single digit state code
us[1] = 1; us[2] = 4; us[3] = 5; us[4] = 6; us[5] = 8; us[6] = 9

US2010.sf <- US2010.sf[US2010.sf$STATEA %in% us,]

US2010.sf <- st_transform(US2010.sf, crs = st_crs(TornB.sf))
```

** This fixes the problem with tidycensus for 2010 ** 

Removing states outside of the contiguous US changes the number of tracts from 74001 to 72359.

Now focus on cleaning up the sf object (combine ages and margins of error)
```{r}
US2010.sf = US2010.sf %>%
  mutate(TotalPop_2010 = TotalPop,
         TotalMale_2010 = TotalMale,
         MaleUnder18_2010 = MaleUnder5 + Male5.9 + Male10.14 + Male15.17,
         Male18to44_2010 = Male18.19 + Male20 + Male21 + Male22.24 + Male25.29 + Male30.34
         + Male35.39 + Male40.44,
         Male45to64_2010 = Male45.49 + Male50.54 + Male55.59 + Male60.61 + Male62.64,
         MaleOver65_2010 = Male65.66 + Male67.69 + Male70.74 + Male75.79 + Male80.84
         + MaleOver85,
         TotalFemale_2010 = TotalFemale,
         FemaleUnder18_2010 = FemaleUnder5 + Female5.9 + Female10.14 + Female15.17,
         Female18to44_2010 = Female18.19 + Female20 + Female21 + Female22.24 + Female25.29
         + Female30.34 + Female35.39 + Female40.44,
         Female45to64_2010 = Female45.49 + Female50.54 + Female55.59 + Female60.61,
         White_2010 = White,
         Black_2010 = Black,
         TotalHousingUnits_2010 = TotalHousingUnits,
         MobileHomes_2010 = MobileHomes,
         MedianIncome_2010 = MedianIncome * 1.032,
         MedianIncomeM_2010 = MedianIncomeM * 1.032)
```

Try areal weighted interpolation

The cookie cutters are the simple feature _polygons_ defining the boundaries we want values interpolated to. This is defined as the target object and it is the first argument in the `aw_interpolate()` function. We need to identify each cookie cutter with a unique target id (`tid`).

The dough is the underlying simple feature _variable_ that we want interpolated. It is defined in a source simple feature data frame (`source =`). Each feature must have a unique id (`sid`). The variable is specified in the `extensive =` argument.

Here the cookie cutters are the damage path POLYGONS and the county-level population estimate is the dough.
```{r}
out2010.sf <- aw_interpolate(TornB.sf, 
               tid = "ID", 
               source = US2010.sf, 
               sid = "ID2",
               extensive = c("TotalPop_2010", "TotalMale_2010", "MaleUnder18_2010",
                             "Male18to44_2010", "Male45to64_2010", "MaleOver65_2010",
                             "TotalFemale_2010", "FemaleUnder18_2010",
                             "Female18to44_2010", "Female45to64_2010",
                             "FemaleOver65_2010", "White_2010",
                             "Black_2010", "TotalHousingUnits_2010", "MobileHomes_2010"),
               intensive = c("MedianIncome_2010"),
               weight = "total", 
               output = "sf")

```

Collect 2000 Census Tract information
```{r}
us = unique(fips_codes$state)[c(1, 3:8, 10:11, 13:51)]

us2000.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract", 
          variables = c("P001001", "P008002", "P008003", "P008004", "P008005", "P008006", "P008007", "P008008", "P008009", "P008010", "P008011", "P008012", "P008013", "P008014", "P008015", "P008016", "P008017", "P008018", "P008019", "P008020", "P008021", "P008022", "P008023", "P008024", "P008025", "P008026", "P008027", "P008028", "P008029", "P008030", "P008031", "P008032", "P008033", "P008034", "P008035", "P008036", "P008037", "P008038", "P008039", "P008040", "P008041", "P008042", "P008043", "P008044", "P008045", "P008046", "P008047", "P008048", "P008049", "P008050", "P008051", "P008052", "P008053", "P008054", "P008055", "P008056", "P008057", "P008058", "P008059", "P008060", "P008061", "P008062", "P008063", "P008064", "P008065", "P008066", "P008067", "P008068", "P008069", "P008070", "P008071", "P008072", "P008073", "P008074", "P008075", "P008076", "P008077", "P008078", "P008079", "P006002", "P006003",  "P053001", "H030001","H030010"),
          year = 2000,
          output = "wide",
          geometry = TRUE)
}),
rbind
)
```

Clean up sf object
```{r}
US2000.sf = us2000.sf %>%
  mutate(TotalPop_2000 = P001001,
         TotalMale_2000 = P008002,
         MaleUnder18_2000 = P008003 + P008004 + P008005 + P008006 + P008007 + P008008 
         + P008009 + P008010 + P008011 + P008012 + P008013 + P008014 + P008015 + P008016 
         + P008017 + P008018 + P008019 + P008020,
         Male18to44_2000 = P008021 + P008022 + P008023 + P008024 + P008025 
         + P008026 + P008027 + P008028 + P008029,
         Male45to64_2000 = P008030 + P008031 + P008032 + P008033 + P008034,
         MaleOver65_2000 = P008035 + P008036 + P008037 + P008038 + P008039 
         + P008040,
         TotalFemale_2000 = P008041,
         FemaleUnder18_2000 = P008042 + P008043 + P008044 + P008045 + P008046 + P008047 
         + P008048 + P008049 + P008050 + P008051 + P008052 + P008053 + P008054 + P008055 
         + P008056 + P008057 + P008058 + P008059,
         Female18to44_2000 = P008060 + P008061 + P008062 + P008063 + P008064 + P008065 
         + P008066 + P008067 + P008068,
         Female45to64_2000 = P008069+ P008070 + P008071 + P008072 + P008073,
         FemaleOver65_2000 = P008074 + P008075 + P008076 + P008077 + P008078 + P008079,
         White_2000 = P006002,
         Black_2000 = P006003,
         TotalHousingUnits_2000 = H030001,
         MobileHomes_2000 = H030010,
         MedianIncome_2000 = P053001 * 1.423)

US2000.sf = US2000.sf %>%
  mutate(ID2 = 1:nrow(us2000.sf))

US2000.sf <- st_transform(US2000.sf, crs = st_crs(TornB.sf))
```

```{r}
out2000.sf <- aw_interpolate(TornB.sf, 
               tid = "ID", 
               source = US2000.sf, 
               sid = "ID2",
               extensive = c("TotalPop_2000", "TotalMale_2000", "MaleUnder18_2000",
                             "Male18to44_2000", "Male45to64_2000", "MaleOver65_2000",
                             "TotalFemale_2000", "FemaleUnder18_2000",
                             "Female18to44_2000", "Female45to64_2000",
                             "FemaleOver65_2000", "White_2000","Black_2000",
                             "TotalHousingUnits_2000", "MobileHomes_2000"),
               intensive = c("MedianIncome_2000"),
               weight = "total", 
               output = "sf")
```

Collect 1990 Census Tract information
```{r}
us = unique(fips_codes$state)[c(1, 3:8, 10:11, 13:51)]

us1990.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract", 
          variables = c("P001001", "P008002", "P008003", "P008004", "P008005", "P008006", "P008007", "P008008", "P008009", "P008010", "P008011", "P008012", "P008013", "P008014", "P008015", "P008016", "P008017", "P008018", "P008019", "P008020", "P008021", "P008022", "P008023", "P008024", "P008025", "P008026", "P008027", "P008028", "P008029", "P008030", "P008031", "P008032", "P008033", "P008034", "P008035", "P008036", "P008037", "P008038", "P008039", "P008040", "P008041", "P008042", "P008043", "P008044", "P008045", "P008046", "P008047", "P008048", "P008049", "P008050", "P008051", "P008052", "P008053", "P008054", "P008055", "P008056", "P008057", "P008058", "P008059", "P008060", "P008061", "P008062", "P008063", "P008064", "P008065", "P008066", "P008067", "P008068", "P008069", "P008070", "P008071", "P008072", "P008073", "P008074", "P008075", "P008076", "P008077", "P008078", "P008079", "P006002", "P006003",  "P053001", "H030001","H030010"),
          year = 1990,
          output = "wide",
          geometry = TRUE)
}),
rbind
)
```


Compare this estimate to our previous estimates

Import `SocialCorrelates.shp` containing the casualty-producing tornadoes 1995-2016 and estimates of socioeconomic and demographic data at the tornado level. Add `Date` and `hr` columns to the data frame.
```{r}
#unzip("SocialCorrelates.zip")
TornSC.sf <- st_read(dsn = "SocialCorrelatesRound", 
                    layer = "SocialCorrelatesRound", 
                    stringsAsFactors = FALSE) %>%
  mutate(Date = as.Date(date),
         hr = hour(DateTim)) %>%
  filter(Year >= 2010)
```

Compare with previous estimates
```{r}
# Find the missing tornadoes
which(!as.character(out$DateTime) %in% as.character(TornSC.sf$DateTim))

# Compare areas
((sum(as.vector(st_area(TornSC.sf))) - sum(as.vector(st_area(out[-403,]))))/ sum(as.vector(st_area(TornSC.sf)))) * 100 

# Percent error
((sum(TornSC.sf$TotlPpl) - sum(out$B01001_001E[-c(403)]))/sum(TornSC.sf$TotlPpl)) * 100

#Pearson Correlation
cor.test(TornSC.sf$TotlPpl, out$B01001_001E[-c(403)])

# RMSE
Diffpop = sum(TornSC.sf$TotlPpl) - sum(out$B01001_001E[-c(403)])
RMSEpop = sqrt((abs(Diffpop)^2)/605)
```

Subset all 2010--2016 tornadoes.
```{r}
Torn2016.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year >= 2010 & Year <= 2016)
```

Subset only 2010 tornadoes.
```{r}
Torn2010.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2010)
```

Because 2010 ACS data is not working with tidycensus. Try 2015 tornadoes instead.
```{r}
Torn2015.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2015)

Torn2013.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2013)
```

Get Census tracts for all contiguous U.S. states. Begin with 2017 tract-level data.
```{r}
us <- unique(fips_codes$state)[c(1, 3:8, 10:11, 13:51)]

counties <- fips_codes %>%
  filter(state %in% us)

options(tigris_use_cache = TRUE)

us2017.sf = reduce(map(us, function(x) {
  get_acs(state = x,
          geography = "tract", 
          variables = ("B01001_001E"),
          year = 2017,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2017.sf <- st_transform(us2017.sf, crs = st_crs(Torn2010.sf))
```

Then collect 2010 ACS tract-level data. Current bug with 2010--2014 ACS 5-years estimates.
```{r}
us2010.sf <- reduce(map(us, function(x) {
  get_acs(state = x,
          county = county_state$COUNTYFP,
          geography = "tract", 
          variables = ("B01001_001E"),
          year = 2011,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2010.sf <- st_transform(us2010.sf, crs = st_crs(Torn2010.sf))
```

Try a work-around. This takes a long time. Split the census tracts into multiple sfdf (otherwise Census API will time out).

Create a function to get data by state.
```{r}
get_state_demographic_data <- function(the_state, the_year) {

# get all counties in given state
  county_state <- tigris::counties(
  state = the_state,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf",
  refresh=TRUE
)
  
# Execute the code
  us2010A.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = c("B01001_001", "B01001_002", "B01001_003", "B01001_004", "B01001_005", "B01001_006", "B01001_007", "B01001_008", "B01001_009", "B01001_010", "B01001_011", "B01001_012", "B01001_013", "B01001_014", "B01001_015", "B01001_016", "B01001_017", "B01001_018", "B01001_019", "B01001_020", "B01001_021", "B01001_022", "B01001_023", "B01001_024", "B01001_025", "B01001_026", "B01001_027", "B01001_028", "B01001_029", "B01001_030", "B01001_031", "B01001_032", "B01001_033", "B01001_034", "B01001_035", "B01001_036", "B01001_037", "B01001_038", "B01001_039", "B01001_040", "B01001_041", "B01001_042", "B01001_043", "B01001_044", "B01001_045", "B01001_046", "B01001_047", "B01001_048", "B01001_049", "B02001_002", "B02001_003", "B19013_001", "B25024_001", "B25024_010"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
}
  
AL.df = get_state_demographic_data("AL", 2010)  
```

Try using tidycensus. Start with only 9 states.
```{r}
my_states <- unique(fips_codes$state)[c(1, 3:8, 10:11)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf",
  refresh=TRUE
)

us2010A.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = c("B01001_001", "B01001_002", "B01001_003", "B01001_004", "B01001_005", "B01001_006", "B01001_007", "B01001_008", "B01001_009", "B01001_010", "B01001_011", "B01001_012", "B01001_013", "B01001_014", "B01001_015", "B01001_016", "B01001_017", "B01001_018", "B01001_019", "B01001_020", "B01001_021", "B01001_022", "B01001_023", "B01001_024", "B01001_025", "B01001_026", "B01001_027", "B01001_028", "B01001_029", "B01001_030", "B01001_031", "B01001_032", "B01001_033", "B01001_034", "B01001_035", "B01001_036", "B01001_037", "B01001_038", "B01001_039", "B01001_040", "B01001_041", "B01001_042", "B01001_043", "B01001_044", "B01001_045", "B01001_046", "B01001_047", "B01001_048", "B01001_049", "B02001_002", "B02001_003", "B19013_001", "B25024_001", "B25024_010"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Then add in the next 20 states.
```{r}
my_states <- unique(fips_codes$state)[c(13:33)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf"
)

us2010B.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = ("B01001_001E"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Then add the last 20 states
```{r}
my_states <- unique(fips_codes$state)[c(34:51)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf"
)

us2010C.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = ("B01001_001E"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Combine the simple features dataframes.
```{r}
x <-  rbind(us2010.sf, us2010B.sf)
us2010.sf <-  rbind(x, us2010C.sf)

us2010.sf <- st_transform(us2010.sf, crs = st_crs(Torn2010.sf))
```


Then collect 2000 Census tract-level data.
```{r}
us2000.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract", 
          variables = ("P001001"),
          year = 2000,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2000.sf <- st_transform(us2000.sf, crs = st_crs(Torn2010.sf))
```

Then collect 1990 Census tract-level data. There is a bug in the tidycensus package related to changes in tract and county differences. For now, use county level data.
```{r}
us1990.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract",
          variables = ("P0010001"),
          year = 1990,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us1990.sf <- st_transform(us1990.sf, crs = st_crs(Torn2010.sf))
```

Find percent error for different years. Begin by interpolating estimates across the 2015 ACS, 2000 Census, and 1990 Census.
```{r}
# 2015
out2015 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us2010.sf, 
               sid = "GEOID", 
               extensive = "B01001_001E",
               weight = "total", 
               output = "sf")

# 2000
out2000 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us2000.sf, 
               sid = "GEOID", 
               extensive = "P001001",
               weight = "total", 
               output = "sf")

# 1990
out1990 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us1990.sf, 
               sid = "GEOID", 
               extensive = "P0010001",
               weight = "total", 
               output = "sf")
```

```{r}
# 2014 tornado paths
df <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df$y <- df$y * 100

# 2013 tornado paths (rerun code)
df2 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out2015$B01001_001E[-57])),  (abs(sum(out2000$P001001[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out2000$P001001[-57])), (abs(sum(out1990$P0010001[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out1990$P0010001[-57]))))

df2$y <- df2$y * 100

# 2012 tornado paths (rerun code)

df3 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df3$y <- df3$y * 100

# 2016 tornado paths (rerun code)

df4 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df4$y <- df4$y * 100

# Plot
ggplot() +
  geom_point(data = df2, aes(x = x, y = y, colour = "red")) +
  geom_point(data = df3, aes(x = x, y = y, colour = "blue")) +
  geom_point(data = df4, aes(x = x, y = y, colour = "green")) + 
  geom_point(data = df, aes(x = x, y = y)) +
  ylab("Percent Error") + xlab("Year of Data") + 
  theme_minimal() +
  theme(legend.position="none")

                
sum(out2015$B01001_001E)
sum(out2000$P001001)
sum(out1990$P0010001)
```







### OLD CODE

Add tornado paths by buffering tornado tracks by associated widths. Need to account for tornadoes without a path (same latitude and longitude).
```{r}
begin.coord <- data.frame(lon=Torn.sf$slon, lat=Torn.sf$slat)
end.coord <- data.frame(lon=Torn.sf$elon, lat=Torn.sf$elat)

l_sf <- vector("list", nrow(Torn.sf))
for (i in seq_along(l_sf)){
  l_sf[[i]] <- st_linestring(as.matrix(rbind(begin.coord[i, ], end.coord[i,])))
}
# Create simple feature geometry list column
l_sfc <- st_sfc(l_sf, crs = "+proj=longlat +datum=WGS84")
# Put new bounding boxes into the geometry column in the sf database and transform the simple features to new projection
Torn.sf$geometry <- l_sfc
st_transform(Torn.sf, crs = "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
```

```{r}
TornSLine = as(Torn.sf, "Spatial")
TornSLine = spTransform(TornSLine, CRS("+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
TornSPoly = gBuffer(TornSLine, byid = TRUE, width = TornSLine$Width/2, capStyle = "SQUARE")
TornSPoly.sf <- st_as_sf(TornSPoly)
```

Calculate the error in area between the estimated paths (AreaPath variable) and the buffered tornado tracks (tornado paths).
```{r}
((sum(Torn.sf$AreaPath) - gArea(TornSPoly))/sum(Torn.sf$AreaPath)) * 100
```

The error is less than 1/10 a percent. The buffer method works.

Plot casualty-producing tornadoes.
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)

tm_shape(stateBorders, projection ="+init=epsg:2163") +
  tm_borders() +
  tm_fill(col = "grey94") +
  tm_shape(TornSPoly) +
  tm_polygons(col = "black") +
  tm_format('World', legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                  legend.frame = FALSE) +
  #tm_format_Europe(legend.position = c("left", "bottom"),
  #                 attr.position = c("left", "bottom"),
  #                 legend.frame = TRUE) +
  tm_scale_bar(position = c("right", "bottom")) +
  #tm_compass(position = c("right", "bottom")) +
  tm_layout(frame = FALSE, attr.outside=TRUE)
```

Plot casualty-producing tornadoes in Ohio over census tracts.
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)
OH = stateBorders[stateBorders$stusps == "OH",]

tm_shape(stateBorders[stateBorders$statefp == 39,], projection ="+init=epsg:2163") +
  tm_borders() +
  tm_fill(col = "grey94") +
  tm_shape(TornOH.sf[10,]) +
  tm_polygons(col = "blue") +
  tm_shape(OH2010.sfdf) + 
  tm_polygons(col = "grey98", alpha = 0.2) +
  tm_format('World', legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                  legend.frame = FALSE) +
  #tm_format_Europe(legend.position = c("left", "bottom"),
  #                 attr.position = c("left", "bottom"),
  #                 legend.frame = TRUE) +
  tm_scale_bar(position = c("right", "bottom")) +
  #tm_compass(position = c("right", "bottom")) +
  tm_layout(frame = FALSE, attr.outside=TRUE)
```

```{r}
get_state_demographic_data <- function(the_state, the_year) {
  
  options(tigris_use_cache = TRUE) #keep chached version of data
  
  # get all counties in given state
  counties <- tidycensus::fips_codes %>%
    dplyr::filter(state == the_state)
  
  # loop over counties and get tracts for each county
  purrr::map(counties$county_code, 
       ~ get_acs(
         geography = 'tract',
         table = c("B19301"),
         state = the_state,
         county = .x,
         year = the_year,
         survey = 'acs5',
         geometry = TRUE)
       ) %>% 
    purrr::reduce(rbind)  # bind rows of all counties
}

get_state_demographic_data(us, 2010)
```
