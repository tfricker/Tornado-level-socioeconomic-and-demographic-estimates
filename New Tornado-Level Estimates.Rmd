---
title: "Tornado-Level Estimates using Areal"
author: "Tyler Fricker"
date: "1/14/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

Set working directory and load packages.
```{r}
library(tidyverse)
library(lubridate)
library(sf)
library(tmap)
library(USAboundaries)
library(rgeos)
library(rgdal)
library(areal)
library(tidycensus)
library(ipumsr)
```

### Data and Methods

Tornado data:

Download the tornado data from the Storm Prediction Center (SPC) http://www.spc.noaa.gov/gis/svrgis/ and load the shapefile into R.
```{r}
#download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-aspath.zip",
#              destfile = "tornado2017.zip")
#download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-initpoint.zip",
#              destfile = "tornado2017.zip")
#unzip("tornado2017.zip")
TornL.sf <- read_sf(dsn = "1950-2017-torn-aspath",
                   stringsAsFactors = FALSE)
TornP.sf <- read_sf(dsn = "1950-2017-torn-initpoint",
                   stringsAsFactors = FALSE)
```

The Paths data set has missing geometries, while the points data set does not.
```{r}
any(is.na(st_dimension(TornL.sf)))
any(is.na(st_dimension(TornP.sf)))
```

Merge the two data sets. Insert point geometries where there are missing linestring geometries.
```{r}
Torn.sf <- TornL.sf
eg <- which(st_is_empty(Torn.sf))
Torn.sf$geometry[eg] <- TornP.sf$geometry[eg]
```

Remove tornadoes occurring in Hawaii, Alaska, and Puerto Rico and those occurring before 1994. That year marks the beginning of comprehensive WSR-88D radar coverage. For missing EF ratings use the modification rules (if/else) defined here: https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf
```{r}
Torn.sf <- Torn.sf %>%
  filter(yr >= 1995,
         !st %in% c("AK", "PR", "HI")) %>%
  mutate(mag = ifelse(mag == -9 & len <= 5, 0, mag),
         mag = ifelse(mag == -9 & len > 5, 1, mag))
```

Add a data/time column also add columns for path length, width, and area in metric units. Leave the time zone as native CDT.
```{r}
Torn.sf <- Torn.sf %>%
  mutate(dy = format(as.Date(date, format="%Y-%m-%d"), "%d"),
         DateTime = as.POSIXct(paste(yr, mo, dy, time), format = "%Y%m%d%H:%M:%S"),
         Hour = hour(DateTime),
         Year = year(DateTime),
         Length = len * 1609.34,
         Length = ifelse(Length == 0, min(Length[Length > 0]), Length), #takes care of zero length
         Width = wid * .9144,
         Width = ifelse(Width == 0, min(Width[Width > 0]), Width), #takes care of zero width
         Width = ifelse(Year >= 1995, Width * pi/4, Width), #takes care of change: avg to max
         cas = inj + fat,
         AreaPath = Length * Width,
         Ma = factor(month.abb[mo], levels = month.abb[1:12])) %>%
         filter(cas > 0) %>%
  sf::st_sf()
max(Torn.sf$yr)
```

Add energy dissipation per tornado.
```{r}
perc <- c(1, 0, 0, 0, 0, 0, 
          .772, .228, 0, 0, 0, 0,
          .616, .268, .115, 0, 0, 0,
          .529, .271, .133, .067, 0, 0,
          .543, .238, .131, .056, .032, 0,
          .538, .223, .119, .07, .033, .017)
percM <- matrix(perc, ncol = 6, byrow = TRUE)
threshW <- c(29.06, 38.45, 49.62, 60.8, 74.21, 89.41)
midptW <- c(diff(threshW)/2 + threshW[-length(threshW)], threshW[length(threshW)] + 7.5)
ef <- Torn.sf$mag + 1
EW3 <- numeric()
for(i in 1:length(ef)) EW3[i] = midptW^3 %*% percM[ef[i], ]
Torn.sf <- Torn.sf %>%
  mutate(ED = EW3 * AreaPath)
```

Add tornado paths by buffering tornado tracks by associated widths.

To perform geocomputions we need to set coordinate reference system. Here it is geographic. We transform the geographic coordinate reference system to a specific Lambert conic conformal projection.
```{r}
Torn.sf <- st_transform(Torn.sf, 
                     crs = "+proj=lcc +lat_1=60 +lat_2=30 +lon_0=-90 +units=m")
```

Buffer the geometries.
```{r}
TornB.sf <- st_buffer(Torn.sf, 
                   dist = Torn.sf$Width/2,
                   endCapStyle = 'ROUND')
```

Calculate the error in area between the estimated paths (AreaPath variable) and the buffered tornado tracks (tornado paths).
```{r}
((sum(TornB.sf$AreaPath) - sum(as.vector(st_area(TornB.sf))))/sum(Torn.sf$AreaPath)) * 100
```

Percent error is between 1.8% (square end caps) and 2.3% (round end caps).

Subset tornadoes from 1995--2016
```{r}
TornB.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year <= 2016)
```

Play with Areal Package and TidyCensus package. Start with a small set of the data and work up.

Socioeconomic/Demographic data:

Load API and variables from ACS. Here we use the 2000 Census summary file 3, and 2010 ACS 5-year estimates.
```{r}
census_api_key("2814de123d5d0461a3347a42849d25106688daa8", install = TRUE, overwrite = TRUE)
v90 = load_variables(1990, "sf3", cache = FALSE)
v00 = load_variables(2000, "sf3", cache = FALSE)
v10 <- load_variables(2010, "acs5", cache = FALSE)
v15 <- load_variables(2015, "acs5", cache = FALSE)
```

Create dataframes of all Tracts. The variables for the Census (2000) and ACS (2010) include:
----------------------------------------------------------------------------------

Total Population (P001001/B01001_001E)
-----------------------------------------
Male Population (P008002/B01001_002E)
Male Population (Under 17) (P008003-P008020/B01001_003E-B01001_006E)
Male Population (18-44) (P008021-P008029/B01001_007E-B01001_0014E)
Male Population (45-64) (P008030-P008034/B01001_015E-B01001_019E)
Male Population (Over 65) (P008035-P008040/B01001_020E-B01001_025E)
-----------------------------------------
Female Population (P008041/B01001_026E)
Female Population (Under 17) (P008042-P008059/B01001_027E-B01001_030E)
Female Population (18-44) (P008060-P008068/B01001_031E-B01001_038E)
Female Population (45-64) (P008069-P008073/B01001_039E-B01001_043E)
Female Population (Over 65) (P008074-P008079/B01001_044E-B01001_049E)
-----------------------------------------
White alone (P006002/B02001_002E)
-----------------------------------------
Black or African-American alone (P006003/B02001_003E)
-----------------------------------------
Household Median Income (P053001/B19013_001E)
-----------------------------------------
Housing Units (H030001/B25024_001)
Mobile Homes (H030010/B25024_010E)
-----------------------------------------

Try downloading shapefile for Census tracts from IPUMS GIS.
```{r}
Tracts_2010.sf <- read_sf(dsn = "2012_Tracts",
                   stringsAsFactors = FALSE) %>%
  mutate(STATEFP = as.numeric(STATEFP))
```

Import IPUMS data
```{r}
us2010 <- read.csv("2012ACS.csv", header = TRUE) %>%
  mutate(GISJOIN = as.character(GISJOIN))
```

Merge the two data sets and remove data from states outside of the contiguous U.S.
```{r}
US2010.sf <- ipums_shape_inner_join(us2010, Tracts_2010.sf, by = "GISJOIN") %>%
  mutate(ID2 = 1:nrow(.)) %>%
     st_as_sf()      

us <- unique(fips_codes$state_code)[c(1, 3:8, 10:11, 13:51)]
# Take care of single digit state code
us[1] = 1; us[2] = 4; us[3] = 5; us[4] = 6; us[5] = 8; us[6] = 9

US2010.sf <- US2010.sf[US2010.sf$STATEA %in% us,]

US2010.sf <- st_transform(US2010.sf, crs = st_crs(TornB.sf))
```

** This fixes the problem with tidycensus for 2010 ** 

Removing states outside of the contiguous US changes the number of tracts from 74001 to 72359.

Now focus on cleaning up the sf object (combine ages and margins of error)
```{r}
US2010.sf = US2010.sf %>%
  mutate(TotalPop_2010 = TotalPop,
         TotalMale_2010 = TotalMale,
         MaleUnder18_2010 = MaleUnder5 + Male5.9 + Male10.14 + Male15.17,
         Male18to44_2010 = Male18.19 + Male20 + Male21 + Male22.24 + Male25.29 + Male30.34
         + Male35.39 + Male40.44,
         Male45to64_2010 = Male45.49 + Male50.54 + Male55.59 + Male60.61 + Male62.64,
         MaleOver65_2010 = Male65.66 + Male67.69 + Male70.74 + Male75.79 + Male80.84
         + MaleOver85,
         TotalFemale_2010 = TotalFemale,
         FemaleUnder18_2010 = FemaleUnder5 + Female5.9 + Female10.14 + Female15.17,
         Female18to44_2010 = Female18.19 + Female20 + Female21 + Female22.24 + Female25.29
         + Female30.34 + Female35.39 + Female40.44,
         Female45to64_2010 = Female45.49 + Female50.54 + Female55.59 + Female60.61 
         + Female62.64,
         FemaleOver65_2010 = Female65.66 + Female67.69 + Female70.74 + Female75.79 
         + Female80.84 + FemaleOver85,
         White_2010 = White,
         Black_2010 = Black,
         TotalHousingUnits_2010 = TotalHousingUnits,
         MobileHomes_2010 = MobileHomes,
         MedianIncome_2010 = MedianIncome * 1.032,
         MedianIncomeM = MedianIncomeM * 1.032)
```

Try areal weighted interpolation

The cookie cutters are the simple feature _polygons_ defining the boundaries we want values interpolated to. This is defined as the target object and it is the first argument in the `aw_interpolate()` function. We need to identify each cookie cutter with a unique target id (`tid`).

The dough is the underlying simple feature _variable_ that we want interpolated. It is defined in a source simple feature data frame (`source =`). Each feature must have a unique id (`sid`). The variable is specified in the `extensive =` argument.

Here the cookie cutters are the damage path POLYGONS and the county-level population estimate is the dough.
```{r}
out2010.sf <- aw_interpolate(TornB.sf, 
               tid = "ID", 
               source = US2010.sf, 
               sid = "ID2",
               extensive = c("TotalPop_2010", "TotalMale_2010", "MaleUnder18_2010",
                             "Male18to44_2010", "Male45to64_2010", "MaleOver65_2010",
                             "TotalFemale_2010", "FemaleUnder18_2010",
                             "Female18to44_2010", "Female45to64_2010",
                             "FemaleOver65_2010", "White_2010",
                             "Black_2010", "TotalHousingUnits_2010", "MobileHomes_2010"),
               intensive = c("MedianIncome_2010"),
               weight = "total", 
               output = "sf")

```

Collect 2000 Census Tract information
```{r}
us = unique(fips_codes$state)[c(1, 3:8, 10:11, 13:51)]

us2000.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract", 
          variables = c("P001001", "P008002", "P008003", "P008004", "P008005", "P008006", "P008007", "P008008", "P008009", "P008010", "P008011", "P008012", "P008013", "P008014", "P008015", "P008016", "P008017", "P008018", "P008019", "P008020", "P008021", "P008022", "P008023", "P008024", "P008025", "P008026", "P008027", "P008028", "P008029", "P008030", "P008031", "P008032", "P008033", "P008034", "P008035", "P008036", "P008037", "P008038", "P008039", "P008040", "P008041", "P008042", "P008043", "P008044", "P008045", "P008046", "P008047", "P008048", "P008049", "P008050", "P008051", "P008052", "P008053", "P008054", "P008055", "P008056", "P008057", "P008058", "P008059", "P008060", "P008061", "P008062", "P008063", "P008064", "P008065", "P008066", "P008067", "P008068", "P008069", "P008070", "P008071", "P008072", "P008073", "P008074", "P008075", "P008076", "P008077", "P008078", "P008079", "P006002", "P006003",  "P053001", "H030001","H030010"),
          year = 2000,
          output = "wide",
          geometry = TRUE)
}),
rbind
)
```

Clean up sf object
```{r}
US2000.sf = us2000.sf %>%
  mutate(TotalPop_2000 = P001001,
         TotalMale_2000 = P008002,
         MaleUnder18_2000 = P008003 + P008004 + P008005 + P008006 + P008007 + P008008 
         + P008009 + P008010 + P008011 + P008012 + P008013 + P008014 + P008015 + P008016 
         + P008017 + P008018 + P008019 + P008020,
         Male18to44_2000 = P008021 + P008022 + P008023 + P008024 + P008025 
         + P008026 + P008027 + P008028 + P008029,
         Male45to64_2000 = P008030 + P008031 + P008032 + P008033 + P008034,
         MaleOver65_2000 = P008035 + P008036 + P008037 + P008038 + P008039 
         + P008040,
         TotalFemale_2000 = P008041,
         FemaleUnder18_2000 = P008042 + P008043 + P008044 + P008045 + P008046 + P008047 
         + P008048 + P008049 + P008050 + P008051 + P008052 + P008053 + P008054 + P008055 
         + P008056 + P008057 + P008058 + P008059,
         Female18to44_2000 = P008060 + P008061 + P008062 + P008063 + P008064 + P008065 
         + P008066 + P008067 + P008068,
         Female45to64_2000 = P008069+ P008070 + P008071 + P008072 + P008073,
         FemaleOver65_2000 = P008074 + P008075 + P008076 + P008077 + P008078 + P008079,
         White_2000 = P006002,
         Black_2000 = P006003,
         TotalHousingUnits_2000 = H030001,
         MobileHomes_2000 = H030010,
         MedianIncome_2000 = P053001 * 1.423)

US2000.sf = US2000.sf %>%
  mutate(ID2 = 1:nrow(us2000.sf))

US2000.sf <- st_transform(US2000.sf, crs = st_crs(TornB.sf))
```

```{r}
out2000.sf <- aw_interpolate(TornB.sf, 
               tid = "ID", 
               source = US2000.sf, 
               sid = "ID2",
               extensive = c("TotalPop_2000", "TotalMale_2000", "MaleUnder18_2000",
                             "Male18to44_2000", "Male45to64_2000", "MaleOver65_2000",
                             "TotalFemale_2000", "FemaleUnder18_2000",
                             "Female18to44_2000", "Female45to64_2000",
                             "FemaleOver65_2000", "White_2000","Black_2000",
                             "TotalHousingUnits_2000", "MobileHomes_2000"),
               intensive = c("MedianIncome_2000"),
               weight = "total", 
               output = "sf")
```

Collect 1990 Census Tract information. Use IPUMS again, because it is cleaner than tidycensus.
```{r}
Tracts_1990.sf <- read_sf(dsn = "1990_Tracts",
                   stringsAsFactors = FALSE)

us1990 <- read.csv("1990Census_1.csv", header = TRUE)

US1990.sf <- ipums_shape_inner_join(us1990, Tracts_1990.sf, by = "GISJOIN") %>%
  mutate(ID2 = 1:nrow(.)) %>%
     st_as_sf() 

us <- unique(fips_codes$state_code)[c(1, 3:8, 10:11, 13:51)]
# Take care of single digit state code
us[1] = 1; us[2] = 4; us[3] = 5; us[4] = 6; us[5] = 8; us[6] = 9

US1990.sf <- US1990.sf[US1990.sf$STATEA %in% us,]

US1990.sf <- st_transform(US1990.sf, crs = st_crs(TornB.sf))
```

Now focus on cleaning up the sf object
```{r}
US1990.sf = US1990.sf %>%
  mutate(TotalPop_1990 = TotalPop,
         TotalMale_1990 = TotalMale,
         MaleUnder18_1990 = round((PopUnder1 + Pop1.2 + Pop3.4 + Pop5 + Pop6 + Pop7.9 
         + Pop10.11 + Pop12.13 + Pop14 + Pop15 + Pop16 + Pop17) * .487),
         Male18to44_1990 = round((Pop18 + Pop19 + Pop20 + Pop21 + Pop22.24 + Pop25.29 
         + Pop30.34 + Pop35.39 + Pop40.44) * .487),
         Male45to64_1990 = round((Pop45.49 + Pop50.54 + Pop55.59 + Pop60.61 + Pop62.64) 
         * .487),
         MaleOver65_1990 = round((Pop65.69 + Pop70.74 + Pop75.79 + Pop80.84 + PopOver85) 
         * .487),
         TotalFemale_1990 = TotalFemale,
         FemaleUnder18_1990 = round((PopUnder1 + Pop1.2 + Pop3.4 + Pop5 + Pop6 + Pop7.9 
         + Pop10.11 + Pop12.13 + Pop14 + Pop15 + Pop16 + Pop17) * .513),
         Female18to44_1990 = round((Pop18 + Pop19 + Pop20 + Pop21 + Pop22.24 + Pop25.29 
         + Pop30.34 + Pop35.39 + Pop40.44) * .513),
         Female45to64_1990 = round((Pop45.49 + Pop50.54 + Pop55.59 + Pop60.61 + Pop62.64) 
         * .513),
         FemaleOver65_1990 = round((Pop65.69 + Pop70.74 + Pop75.79 + Pop80.84 + PopOver85)
         * .513),
         White_1990 = White,
         Black_1990 = Black,
         TotalHousingUnits_1990 = TotalHousingUnits,
         MobileHomes_1990 = MobileHomes,
         MedianIncome_1990 = round(MedianIncome * 1.9114))
```

```{r}
out1990.sf <- aw_interpolate(TornB.sf, 
               tid = "ID", 
               source = US1990.sf, 
               sid = "ID2",
               extensive = c("TotalPop_1990", "TotalMale_1990", "MaleUnder18_1990",
                             "Male18to44_1990", "Male45to64_1990", "MaleOver65_1990",
                             "TotalFemale_1990", "FemaleUnder18_1990",
                             "Female18to44_1990", "Female45to64_1990",
                             "FemaleOver65_1990", "White_1990","Black_1990",
                             "TotalHousingUnits_1990", "MobileHomes_1990"),
               intensive = c("MedianIncome_1990"),
               weight = "total", 
               output = "sf")
```

Now there are three sf objects with interpolated variables (out2010.sf, out2000.sf, out1990.sf). Linearily interpolate these values for the specific year of tornado occurrence.
```{r}
df = merge(data.frame(out1990.sf), data.frame(out2000.sf))
df = merge(df, data.frame(out2010.sf)) %>%
  arrange(ID) %>%
  mutate(geometry = out1990.sf$geometry)

# Find which columns to leave out
which(colnames(df) == "TotalPop_2010")
which(colnames(df) == "TotalPop_2000")
which(colnames(df) == "TotalPop_1990")

df1 = df[,1:65] %>%
  filter(Year <= 1999)

df2 = df[, c(1:33,50:81)] %>%
  filter(Year >= 2000)
```

Clean up the data frames. Start with missing 2000 data.
```{r}
# Total Pop
df1$TotalPop_2000[is.na(df1$TotalPop_2000)] = df1$TotalPop_1990[is.na(df1$TotalPop_2000)]

# Males
df1$TotalMale_2000[is.na(df1$TotalMale_2000)] = df1$TotalMale_1990[is.na(df1$TotalMale_2000)]
df1$MaleUnder18_2000[is.na(df1$MaleUnder18_2000)] = df1$MaleUnder18_1990[is.na(df1$MaleUnder18_2000)]
df1$Male18to44_2000[is.na(df1$Male18to44_2000)] = df1$Male18to44_1990[is.na(df1$Male18to44_2000)]
df1$Male45to64_2000[is.na(df1$Male45to64_2000)] = df1$Male45to64_1990[is.na(df1$Male45to64_2000)]
df1$MaleOver65_2000[is.na(df1$MaleOver65_2000)] = df1$MaleOver65_1990[is.na(df1$MaleOver65_2000)]

# Females
df1$TotalFemale_2000[is.na(df1$TotalFemale_2000)] = df1$TotalFemale_1990[is.na(df1$TotalFemale_2000)]
df1$FemaleUnder18_2000[is.na(df1$FemaleUnder18_2000)] = df1$FemaleUnder18_1990[is.na(df1$FemaleUnder18_2000)]
df1$Female18to44_2000[is.na(df1$Female18to44_2000)] = df1$Female18to44_1990[is.na(df1$Female18to44_2000)]
df1$Female45to64_2000[is.na(df1$Female45to64_2000)] = df1$Female45to64_1990[is.na(df1$Female45to64_2000)]
df1$FemaleOver65_2000[is.na(df1$FemaleOver65_2000)] = df1$FemaleOver65_1990[is.na(df1$FemaleOver65_2000)]

# White and Black
df1$White_2000[is.na(df1$White_2000)] = df1$White_1990[is.na(df1$White_2000)]
df1$Black_2000[is.na(df1$Black_2000)] = df1$Black_1990[is.na(df1$Black_2000)]

# Housing Units and Mobile Homes
df1$TotalHousingUnits_2000[is.na(df1$TotalHousingUnits_2000)] = df1$TotalHousingUnits_1990[is.na(df1$TotalHousingUnits_2000)]
df1$MobileHomes_2000[is.na(df1$MobileHomes_2000)] = df1$MobileHomes_1990[is.na(df1$MobileHomes_2000)]

# Median Income
df1$MedianIncome_2000[is.na(df1$MedianIncome_2000)] = df1$MedianIncome_1990[is.na(df1$MedianIncome_2000)]
```

Then move to missing 1990 data.
```{r}
# Total Pop
df1$TotalPop_1990[is.na(df1$TotalPop_1990)] = df1$TotalPop_2000[is.na(df1$TotalPop_1990)]

# Males
df1$TotalMale_1990[is.na(df1$TotalMale_1990)] = df1$TotalMale_2000[is.na(df1$TotalMale_1990)]
df1$MaleUnder18_1990[is.na(df1$MaleUnder18_1990)] = df1$MaleUnder18_2000[is.na(df1$MaleUnder18_1990)]
df1$Male18to44_1990[is.na(df1$Male18to44_1990)] = df1$Male18to44_2000[is.na(df1$Male18to44_1990)]
df1$Male45to64_1990[is.na(df1$Male45to64_1990)] = df1$Male45to64_2000[is.na(df1$Male45to64_1990)]
df1$MaleOver65_1990[is.na(df1$MaleOver65_1990)] = df1$MaleOver65_2000[is.na(df1$MaleOver65_1990)]

# Females
df1$TotalFemale_1990[is.na(df1$TotalFemale_1990)] = df1$TotalFemale_2000[is.na(df1$TotalFemale_1990)]
df1$FemaleUnder18_1990[is.na(df1$FemaleUnder18_1990)] = df1$FemaleUnder18_2000[is.na(df1$FemaleUnder18_1990)]
df1$Female18to44_1990[is.na(df1$Female18to44_1990)] = df1$Female18to44_2000[is.na(df1$Female18to44_1990)]
df1$Female45to64_1990[is.na(df1$Female45to64_1990)] = df1$Female45to64_2000[is.na(df1$Female45to64_1990)]
df1$FemaleOver65_1990[is.na(df1$FemaleOver65_1990)] = df1$FemaleOver65_2000[is.na(df1$FemaleOver65_1990)]

# White and Black
df1$White_1990[is.na(df1$White_1990)] = df1$White_2000[is.na(df1$White_1990)]
df1$Black_1990[is.na(df1$Black_1990)] = df1$Black_2000[is.na(df1$Black_1990)]

# Housing Units and Mobile Homes
df1$TotalHousingUnits_1990[is.na(df1$TotalHousingUnits_1990)] = df1$TotalHousingUnits_2000[is.na(df1$TotalHousingUnits_1990)]
df1$MobileHomes_1990[is.na(df1$MobileHomes_1990)] = df1$MobileHomes_2000[is.na(df1$MobileHomes_1990)]

# Median Income
df1$MedianIncome_1990[is.na(df1$MedianIncome_1990)] = df1$MedianIncome_2000[is.na(df1$MedianIncome_1990)]

df1 = na.omit(df1)
```

Read in the linear interpolation function
```{r}
lin_interpolate = function(x, y1, y2, data){
data = data
interp = numeric()
for(i in 1:nrow(data)){
  interp[i] = approx(x = x, 
                  y = c(y1[i], y2[i]), 
                  xout = data$Year[i],
                  rule = 2)$y
}
return(interp)
}
```

Run the function for 1990--1999 tornadoes
```{r}
# Total Population

interpPop = lin_interpolate(c(1990, 2000), df1$TotalPop_1990, df1$TotalPop_2000, df1)

# Male Population
interpMales = lin_interpolate(c(1990, 2000), df1$TotalMale_1990, df1$TotalMale_2000, df1)
interpMalesUnder18 = lin_interpolate(c(1990, 2000), df1$MaleUnder18_1990, df1$MaleUnder18_2000, df1)
interpMales18to44 = lin_interpolate(c(1990, 2000), df1$Male18to44_1990, df1$Male18to44_2000, df1)
interpMales45to64 = lin_interpolate(c(1990, 2000), df1$Male45to64_1990, df1$Male45to64_2000, df1)
interpMalesOver65 = lin_interpolate(c(1990, 2000), df1$MaleOver65_1990, df1$MaleOver65_2000, df1)

# Female Population
interpFemales = lin_interpolate(c(1990, 2000), df1$TotalFemale_1990, df1$TotalFemale_2000, df1)
interpFemalesUnder18 = lin_interpolate(c(1990, 2000), df1$FemaleUnder18_1990, df1$FemaleUnder18_2000, df1)
interpFemales18to44 = lin_interpolate(c(1990, 2000), df1$Female18to44_1990, df1$Female18to44_2000, df1)
interpFemales45to64 = lin_interpolate(c(1990, 2000), df1$Female45to64_1990, df1$Female45to64_2000, df1)
interpFemalesOver65 = lin_interpolate(c(1990, 2000), df1$FemaleOver65_1990, df1$FemaleOver65_2000, df1)

# White and Black
interpWhite = lin_interpolate(c(1990, 2000), df1$White_1990, df1$White_2000, df1)
interpBlack = lin_interpolate(c(1990, 2000), df1$Black_1990, df1$Black_2000, df1)

# Housing Units and Mobile Homes
interpHousingUnits = lin_interpolate(c(1990, 2000), df1$TotalHousingUnits_1990, df1$TotalHousingUnits_2000, df1)
interpMobileHomes = lin_interpolate(c(1990, 2000), df1$MobileHomes_1990, df1$MobileHomes_2000, df1)

# Median Income
interpInc = lin_interpolate(c(1990, 2000), df1$MedianIncome_1990, df1$MedianIncome_2000, df1)
```

Now pair the interpolations to variables in the dataframe.
```{r}
df1$TotalPop = interpPop
df1$TotalMale = interpMales
df1$MaleUnder18 = interpMalesUnder18
df1$Male18to44 = interpMales18to44
df1$Male45to64 = interpMales45to64
df1$MaleOver65 = interpMalesOver65
df1$TotalFemale = interpFemales
df1$FemaleUnder18 = interpFemalesUnder18
df1$Female18to44 = interpFemales18to44
df1$Female45to64 = interpFemales45to64
df1$FemaleOver65 = interpFemalesOver65
df1$White = interpWhite
df1$Black = interpBlack
df1$TotalHousingUnits = interpHousingUnits
df1$MobileHomes = interpMobileHomes
df1$MedianIncome = interpInc
```

Run the same code for the 2000--2010 data. Start with missing 2010 data.
```{r}
# Total Pop
df2$TotalPop_2010[is.na(df2$TotalPop_2010)] = df2$TotalPop_2000[is.na(df2$TotalPop_2010)]

# Males
df2$TotalMale_2010[is.na(df2$TotalMale_2010)] = df2$TotalMale_2000[is.na(df2$TotalMale_2010)]
df2$MaleUnder18_2010[is.na(df2$MaleUnder18_2010)] = df2$MaleUnder18_2000[is.na(df2$MaleUnder18_2010)]
df2$Male18to44_2010[is.na(df2$Male18to44_2010)] = df2$Male18to44_2000[is.na(df2$Male18to44_2010)]
df2$Male45to64_2010[is.na(df2$Male45to64_2010)] = df2$Male45to64_2000[is.na(df2$Male45to64_2010)]
df2$MaleOver65_2010[is.na(df2$MaleOver65_2010)] = df2$MaleOver65_2000[is.na(df2$MaleOver65_2010)]

# Females
df2$TotalFemale_2010[is.na(df2$TotalFemale_2010)] = df2$TotalFemale_2000[is.na(df2$TotalFemale_2010)]
df2$FemaleUnder18_2010[is.na(df2$FemaleUnder18_2010)] = df2$FemaleUnder18_2000[is.na(df2$FemaleUnder18_2010)]
df2$Female18to44_2010[is.na(df2$Female18to44_2010)] = df2$Female18to44_2000[is.na(df2$Female18to44_2010)]
df2$Female45to64_2010[is.na(df2$Female45to64_2010)] = df2$Female45to64_2000[is.na(df2$Female45to64_2010)]
df2$FemaleOver65_2010[is.na(df2$FemaleOver65_2010)] = df2$FemaleOver65_2000[is.na(df2$FemaleOver65_2010)]

# White and Black
df2$White_2010[is.na(df2$White_2010)] = df2$White_2000[is.na(df2$White_2010)]
df2$Black_2010[is.na(df2$Black_2010)] = df2$Black_2000[is.na(df2$Black_2010)]

# Housing Units and Mobile Homes
df2$TotalHousingUnits_2010[is.na(df2$TotalHousingUnits_2010)] = df2$TotalHousingUnits_2000[is.na(df2$TotalHousingUnits_2010)]
df2$MobileHomes_2010[is.na(df2$MobileHomes_2010)] = df2$MobileHomes_2000[is.na(df2$MobileHomes_2010)]

# Median Income
df2$MedianIncome_2010[is.na(df2$MedianIncome_2010)] = df2$MedianIncome_2000[is.na(df2$MedianIncome_2010)]
```

Next, move onto missing 2000 data.
```{r}
# Total Pop
df2$TotalPop_2000[is.na(df2$TotalPop_2000)] = df2$TotalPop_2010[is.na(df2$TotalPop_2000)]

# Males
df2$TotalMale_2000[is.na(df2$TotalMale_2000)] = df2$TotalMale_2010[is.na(df2$TotalMale_2000)]
df2$MaleUnder18_2000[is.na(df2$MaleUnder18_2000)] = df2$MaleUnder18_2010[is.na(df2$MaleUnder18_2000)]
df2$Male18to44_2000[is.na(df2$Male18to44_2000)] = df2$Male18to44_2010[is.na(df2$Male18to44_2000)]
df2$Male45to64_2000[is.na(df2$Male45to64_2000)] = df2$Male45to64_2010[is.na(df2$Male45to64_2000)]
df2$MaleOver65_2000[is.na(df2$MaleOver65_2000)] = df2$MaleOver65_2010[is.na(df2$MaleOver65_2000)]

# Females
df2$TotalFemale_2000[is.na(df2$TotalFemale_2000)] = df2$TotalFemale_2010[is.na(df2$TotalFemale_2000)]
df2$FemaleUnder18_2000[is.na(df2$FemaleUnder18_2000)] = df2$FemaleUnder18_2010[is.na(df2$FemaleUnder18_2000)]
df2$Female18to44_2000[is.na(df2$Female18to44_2000)] = df2$Female18to44_2010[is.na(df2$Female18to44_2000)]
df2$Female45to64_2000[is.na(df2$Female45to64_2000)] = df2$Female45to64_2010[is.na(df2$Female45to64_2000)]
df2$FemaleOver65_2000[is.na(df2$FemaleOver65_2000)] = df2$FemaleOver65_2010[is.na(df2$FemaleOver65_2000)]

# White and Black
df2$White_2000[is.na(df2$White_2000)] = df2$White_2010[is.na(df2$White_2000)]
df2$Black_2000[is.na(df2$Black_2000)] = df2$Black_2010[is.na(df2$Black_2000)]

# Housing Units and Mobile Homes
df2$TotalHousingUnits_2000[is.na(df2$TotalHousingUnits_2000)] = df2$TotalHousingUnits_2010[is.na(df2$TotalHousingUnits_2000)]
df2$MobileHomes_2000[is.na(df2$MobileHomes_2000)] = df2$MobileHomes_2010[is.na(df2$MobileHomes_2000)]

# Median Income
df2$MedianIncome_2000[is.na(df2$MedianIncome_2000)] = df2$MedianIncome_2010[is.na(df2$MedianIncome_2000)]

df2 = na.omit(df2)
```

Run the function for 2000--2016 tornadoes
```{r}
# Total Population

interpPop = lin_interpolate(c(2000, 2010), df2$TotalPop_2000, df2$TotalPop_2010, df2)

# Male Population
interpMales = lin_interpolate(c(2000, 2010), df2$TotalMale_2000, df2$TotalMale_2010, df2)
interpMalesUnder18 = lin_interpolate(c(2000, 2010), df2$MaleUnder18_2000, df2$MaleUnder18_2010, df2)
interpMales18to44 = lin_interpolate(c(2000, 2010), df2$Male18to44_2000, df2$Male18to44_2010, df2)
interpMales45to64 = lin_interpolate(c(2000, 2010), df2$Male45to64_2000, df2$Male45to64_2010, df2)
interpMalesOver65 = lin_interpolate(c(2000, 2010), df2$MaleOver65_2000, df2$MaleOver65_2010, df2)

# Female Population
interpFemales = lin_interpolate(c(2000, 2010), df2$TotalFemale_2000, df2$TotalFemale_2010, df2)
interpFemalesUnder18 = lin_interpolate(c(2000, 2010), df2$FemaleUnder18_2000, df2$FemaleUnder18_2010, df2)
interpFemales18to44 = lin_interpolate(c(2000, 2010), df2$Female18to44_2000, df2$Female18to44_2010, df2)
interpFemales45to64 = lin_interpolate(c(2000, 2010), df2$Female45to64_2000, df2$Female45to64_2010, df2)
interpFemalesOver65 = lin_interpolate(c(2000, 2010), df2$FemaleOver65_2000, df2$FemaleOver65_2010, df2)

# White and Black
interpWhite = lin_interpolate(c(2000, 2010), df2$White_2000, df2$White_2010, df2)
interpBlack = lin_interpolate(c(2000, 2010), df2$Black_2000, df2$Black_2010, df2)

# Housing Units and Mobile Homes
interpHousingUnits = lin_interpolate(c(2000, 2010), df2$TotalHousingUnits_2000, df2$TotalHousingUnits_2010, df2)
interpMobileHomes = lin_interpolate(c(2000, 2010), df2$MobileHomes_2000, df2$MobileHomes_2010, df2)

# Median Income
interpInc = lin_interpolate(c(2000, 2010), df2$MedianIncome_2000, df2$MedianIncome_2010, df2)
```

Now pair the interpolations to variables in the dataframe.
```{r}
df2$TotalPop = interpPop
df2$TotalMale = interpMales
df2$MaleUnder18 = interpMalesUnder18
df2$Male18to44 = interpMales18to44
df2$Male45to64 = interpMales45to64
df2$MaleOver65 = interpMalesOver65
df2$TotalFemale = interpFemales
df2$FemaleUnder18 = interpFemalesUnder18
df2$Female18to44 = interpFemales18to44
df2$Female45to64 = interpFemales45to64
df2$FemaleOver65 = interpFemalesOver65
df2$White = interpWhite
df2$Black = interpBlack
df2$TotalHousingUnits = interpHousingUnits
df2$MobileHomes = interpMobileHomes
df2$MedianIncome = interpInc
```

Merge the two data frames now
```{r}
# Find which columns to leave out
which(colnames(df1) == "TotalPop_1990")
which(colnames(df1) == "TotalPop")
which(colnames(df2) == "TotalPop_2000")


Early.df <- df1[,-c(34:65)]
Late.df <- df2[,-c(34:65)]

SocialCorrelates.sf <- rbind(Early.df, Late.df) %>%
  mutate(ID = 1:nrow(.)) %>%
  st_as_sf()

st_write(SocialCorrelates.sf, "SocialCorrelatesNew.shp")

```









Compare this estimate to our previous estimates

Import `SocialCorrelates.shp` containing the casualty-producing tornadoes 1995-2016 and estimates of socioeconomic and demographic data at the tornado level. Add `Date` and `hr` columns to the data frame.
```{r}
#unzip("SocialCorrelates.zip")
TornSC.sf <- st_read(dsn = "SocialCorrelatesRound", 
                    layer = "SocialCorrelatesRound", 
                    stringsAsFactors = FALSE) %>%
  mutate(Date = as.Date(date),
         hr = hour(DateTim)) %>%
  filter(Year >= 2010)
```

Compare with previous estimates
```{r}
# Find the missing tornadoes
which(!as.character(out$DateTime) %in% as.character(TornSC.sf$DateTim))

# Compare areas
((sum(as.vector(st_area(TornSC.sf))) - sum(as.vector(st_area(out[-403,]))))/ sum(as.vector(st_area(TornSC.sf)))) * 100 

# Percent error
((sum(TornSC.sf$TotlPpl) - sum(out$B01001_001E[-c(403)]))/sum(TornSC.sf$TotlPpl)) * 100

#Pearson Correlation
cor.test(TornSC.sf$TotlPpl, out$B01001_001E[-c(403)])

# RMSE
Diffpop = sum(TornSC.sf$TotlPpl) - sum(out$B01001_001E[-c(403)])
RMSEpop = sqrt((abs(Diffpop)^2)/605)
```

Subset all 2010--2016 tornadoes.
```{r}
Torn2016.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year >= 2010 & Year <= 2016)
```

Subset only 2010 tornadoes.
```{r}
Torn2010.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2010)
```

Because 2010 ACS data is not working with tidycensus. Try 2015 tornadoes instead.
```{r}
Torn2015.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2015)

Torn2013.sf <- TornB.sf %>%
  mutate(ID = 1:nrow(TornB.sf)) %>%
  filter(Year == 2013)
```

Get Census tracts for all contiguous U.S. states. Begin with 2017 tract-level data.
```{r}
us <- unique(fips_codes$state)[c(1, 3:8, 10:11, 13:51)]

counties <- fips_codes %>%
  filter(state %in% us)

options(tigris_use_cache = TRUE)

us2017.sf = reduce(map(us, function(x) {
  get_acs(state = x,
          geography = "tract", 
          variables = ("B01001_001E"),
          year = 2017,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2017.sf <- st_transform(us2017.sf, crs = st_crs(Torn2010.sf))
```

Then collect 2010 ACS tract-level data. Current bug with 2010--2014 ACS 5-years estimates.
```{r}
us2010.sf <- reduce(map(us, function(x) {
  get_acs(state = x,
          county = county_state$COUNTYFP,
          geography = "tract", 
          variables = ("B01001_001E"),
          year = 2011,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2010.sf <- st_transform(us2010.sf, crs = st_crs(Torn2010.sf))
```

Try a work-around. This takes a long time. Split the census tracts into multiple sfdf (otherwise Census API will time out).

Create a function to get data by state.
```{r}
get_state_demographic_data <- function(the_state, the_year) {

# get all counties in given state
  county_state <- tigris::counties(
  state = the_state,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf",
  refresh=TRUE
)
  
# Execute the code
  us2010A.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = c("B01001_001", "B01001_002", "B01001_003", "B01001_004", "B01001_005", "B01001_006", "B01001_007", "B01001_008", "B01001_009", "B01001_010", "B01001_011", "B01001_012", "B01001_013", "B01001_014", "B01001_015", "B01001_016", "B01001_017", "B01001_018", "B01001_019", "B01001_020", "B01001_021", "B01001_022", "B01001_023", "B01001_024", "B01001_025", "B01001_026", "B01001_027", "B01001_028", "B01001_029", "B01001_030", "B01001_031", "B01001_032", "B01001_033", "B01001_034", "B01001_035", "B01001_036", "B01001_037", "B01001_038", "B01001_039", "B01001_040", "B01001_041", "B01001_042", "B01001_043", "B01001_044", "B01001_045", "B01001_046", "B01001_047", "B01001_048", "B01001_049", "B02001_002", "B02001_003", "B19013_001", "B25024_001", "B25024_010"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
}
  
AL.df = get_state_demographic_data("AL", 2010)  
```

Try using tidycensus. Start with only 9 states.
```{r}
my_states <- unique(fips_codes$state)[c(1, 3:8, 10:11)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf",
  refresh=TRUE
)

us2010A.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = c("B01001_001", "B01001_002", "B01001_003", "B01001_004", "B01001_005", "B01001_006", "B01001_007", "B01001_008", "B01001_009", "B01001_010", "B01001_011", "B01001_012", "B01001_013", "B01001_014", "B01001_015", "B01001_016", "B01001_017", "B01001_018", "B01001_019", "B01001_020", "B01001_021", "B01001_022", "B01001_023", "B01001_024", "B01001_025", "B01001_026", "B01001_027", "B01001_028", "B01001_029", "B01001_030", "B01001_031", "B01001_032", "B01001_033", "B01001_034", "B01001_035", "B01001_036", "B01001_037", "B01001_038", "B01001_039", "B01001_040", "B01001_041", "B01001_042", "B01001_043", "B01001_044", "B01001_045", "B01001_046", "B01001_047", "B01001_048", "B01001_049", "B02001_002", "B02001_003", "B19013_001", "B25024_001", "B25024_010"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Then add in the next 20 states.
```{r}
my_states <- unique(fips_codes$state)[c(13:33)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf"
)

us2010B.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = ("B01001_001E"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Then add the last 20 states
```{r}
my_states <- unique(fips_codes$state)[c(34:51)]

county_state <- tigris::counties(
  state = my_states,
  cb = TRUE,
  resolution = "20m",
  year = "2010",
  class = "sf"
)

us2010C.sf <- reduce(
    map2(
    .x = county_state$STATEFP,
    .y = county_state$COUNTYFP,
    ~ get_acs(
        state = .x,
        county = .y,
        geography = "tract", 
        variables = ("B01001_001E"),
        year = 2010,
        output = "wide",
        geometry = TRUE
        )
      ),
    rbind
   )
```

Combine the simple features dataframes.
```{r}
x <-  rbind(us2010.sf, us2010B.sf)
us2010.sf <-  rbind(x, us2010C.sf)

us2010.sf <- st_transform(us2010.sf, crs = st_crs(Torn2010.sf))
```


Then collect 2000 Census tract-level data.
```{r}
us2000.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract", 
          variables = ("P001001"),
          year = 2000,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us2000.sf <- st_transform(us2000.sf, crs = st_crs(Torn2010.sf))
```

Then collect 1990 Census tract-level data. There is a bug in the tidycensus package related to changes in tract and county differences. For now, use county level data.
```{r}
us1990.sf = reduce(map(us, function(x) {
  get_decennial(state = x,
          geography = "tract",
          variables = ("P0010001"),
          year = 1990,
          output = "wide",
          geometry = TRUE)
}),
rbind
)

us1990.sf <- st_transform(us1990.sf, crs = st_crs(Torn2010.sf))
```

Find percent error for different years. Begin by interpolating estimates across the 2015 ACS, 2000 Census, and 1990 Census.
```{r}
# 2015
out2015 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us2010.sf, 
               sid = "GEOID", 
               extensive = "B01001_001E",
               weight = "total", 
               output = "sf")

# 2000
out2000 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us2000.sf, 
               sid = "GEOID", 
               extensive = "P001001",
               weight = "total", 
               output = "sf")

# 1990
out1990 <- aw_interpolate(Torn2016.sf, 
               tid = "ID", 
               source = us1990.sf, 
               sid = "GEOID", 
               extensive = "P0010001",
               weight = "total", 
               output = "sf")
```

```{r}
# 2014 tornado paths
df <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df$y <- df$y * 100

# 2013 tornado paths (rerun code)
df2 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out2015$B01001_001E[-57])),  (abs(sum(out2000$P001001[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out2000$P001001[-57])), (abs(sum(out1990$P0010001[-57]) - sum(out2015$B01001_001E[-57]))/ sum(out1990$P0010001[-57]))))

df2$y <- df2$y * 100

# 2012 tornado paths (rerun code)

df3 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df3$y <- df3$y * 100

# 2016 tornado paths (rerun code)

df4 <-  data.frame(x = c(2015, 2000, 1990), 
                y = c((abs(sum(out2015$B01001_001E) - sum(out2015$B01001_001E))/ sum(out2015$B01001_001E)),  (abs(sum(out2000$P001001) - sum(out2015$B01001_001E))/ sum(out2000$P001001)), (abs(sum(out1990$P0010001) - sum(out2015$B01001_001E))/ sum(out1990$P0010001))))

df4$y <- df4$y * 100

# Plot
ggplot() +
  geom_point(data = df2, aes(x = x, y = y, colour = "red")) +
  geom_point(data = df3, aes(x = x, y = y, colour = "blue")) +
  geom_point(data = df4, aes(x = x, y = y, colour = "green")) + 
  geom_point(data = df, aes(x = x, y = y)) +
  ylab("Percent Error") + xlab("Year of Data") + 
  theme_minimal() +
  theme(legend.position="none")

                
sum(out2015$B01001_001E)
sum(out2000$P001001)
sum(out1990$P0010001)
```







### OLD CODE

Add tornado paths by buffering tornado tracks by associated widths. Need to account for tornadoes without a path (same latitude and longitude).
```{r}
begin.coord <- data.frame(lon=Torn.sf$slon, lat=Torn.sf$slat)
end.coord <- data.frame(lon=Torn.sf$elon, lat=Torn.sf$elat)

l_sf <- vector("list", nrow(Torn.sf))
for (i in seq_along(l_sf)){
  l_sf[[i]] <- st_linestring(as.matrix(rbind(begin.coord[i, ], end.coord[i,])))
}
# Create simple feature geometry list column
l_sfc <- st_sfc(l_sf, crs = "+proj=longlat +datum=WGS84")
# Put new bounding boxes into the geometry column in the sf database and transform the simple features to new projection
Torn.sf$geometry <- l_sfc
st_transform(Torn.sf, crs = "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
```

```{r}
TornSLine = as(Torn.sf, "Spatial")
TornSLine = spTransform(TornSLine, CRS("+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
TornSPoly = gBuffer(TornSLine, byid = TRUE, width = TornSLine$Width/2, capStyle = "SQUARE")
TornSPoly.sf <- st_as_sf(TornSPoly)
```

Calculate the error in area between the estimated paths (AreaPath variable) and the buffered tornado tracks (tornado paths).
```{r}
((sum(Torn.sf$AreaPath) - gArea(TornSPoly))/sum(Torn.sf$AreaPath)) * 100
```

The error is less than 1/10 a percent. The buffer method works.

Plot casualty-producing tornadoes.
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)

tm_shape(stateBorders, projection ="+init=epsg:2163") +
  tm_borders() +
  tm_fill(col = "grey94") +
  tm_shape(TornSPoly) +
  tm_polygons(col = "black") +
  tm_format('World', legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                  legend.frame = FALSE) +
  #tm_format_Europe(legend.position = c("left", "bottom"),
  #                 attr.position = c("left", "bottom"),
  #                 legend.frame = TRUE) +
  tm_scale_bar(position = c("right", "bottom")) +
  #tm_compass(position = c("right", "bottom")) +
  tm_layout(frame = FALSE, attr.outside=TRUE)
```

Plot casualty-producing tornadoes in Ohio over census tracts.
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)
OH = stateBorders[stateBorders$stusps == "OH",]

tm_shape(stateBorders[stateBorders$statefp == 39,], projection ="+init=epsg:2163") +
  tm_borders() +
  tm_fill(col = "grey94") +
  tm_shape(TornOH.sf[10,]) +
  tm_polygons(col = "blue") +
  tm_shape(OH2010.sfdf) + 
  tm_polygons(col = "grey98", alpha = 0.2) +
  tm_format('World', legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                  legend.frame = FALSE) +
  #tm_format_Europe(legend.position = c("left", "bottom"),
  #                 attr.position = c("left", "bottom"),
  #                 legend.frame = TRUE) +
  tm_scale_bar(position = c("right", "bottom")) +
  #tm_compass(position = c("right", "bottom")) +
  tm_layout(frame = FALSE, attr.outside=TRUE)
```

```{r}
get_state_demographic_data <- function(the_state, the_year) {
  
  options(tigris_use_cache = TRUE) #keep chached version of data
  
  # get all counties in given state
  counties <- tidycensus::fips_codes %>%
    dplyr::filter(state == the_state)
  
  # loop over counties and get tracts for each county
  purrr::map(counties$county_code, 
       ~ get_acs(
         geography = 'tract',
         table = c("B19301"),
         state = the_state,
         county = .x,
         year = the_year,
         survey = 'acs5',
         geometry = TRUE)
       ) %>% 
    purrr::reduce(rbind)  # bind rows of all counties
}

get_state_demographic_data(us, 2010)
```
